{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7427dcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from shutil import copyfile\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5ed845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new transform with additional data augmentations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ccd85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir_train = os.path.join('D:/The Face data set with the new sort/test_younas_data/face_recognition/train')\n",
    "dataset_dir_test = os.path.join('D:/The Face data set with the new sort/test_younas_data/face_recognition/test')\n",
    "dataset_dir_val = os.path.join('D:/The Face data set with the new sort/test_younas_data/face_recognition/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fec70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.ImageFolder(dataset_dir_test, transform=transform)\n",
    "train_dataset = datasets.ImageFolder(dataset_dir_train, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(dataset_dir_val, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3a1c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = os.listdir(dataset_dir_test)\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f1ccad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Uncomment the model you would like to use\n",
    "\n",
    "\n",
    "\n",
    "###### the alexnet here\n",
    "# model = models.alexnet(pretrained=False)\n",
    "# model.classifier[6]=nn.Linear(4096,num_classes)\n",
    "# Use a pre-trained model\n",
    "\n",
    "###### the convnext_base here\n",
    "# model = models.convnext_base(pretrained=True)\n",
    "# model.classifier[2]=nn.Linear(1024,num_classes)\n",
    "\n",
    "\n",
    "###### the resnet50 here\n",
    "# model = models.resnet50(pretrained=False)\n",
    "# num_features = model.fc.in_features\n",
    "# model.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "\n",
    "###### the vgg16 here\n",
    "# model = models.vgg16(pretrained=False) # pretrained=False just for debug reasons\n",
    "# model.classifier[6]=nn.Linear(4096,num_classes)\n",
    "\n",
    "###### the efficientnet_b7 here\n",
    "# model = models.efficientnet_b7(pretrained=False)\n",
    "# model.classifier[1]=nn.Linear(2560,num_classes)\n",
    "\n",
    "\n",
    "\n",
    "###### the mobilenet_v3_large here\n",
    "# model = models.mobilenet_v3_large(pretrained=False)\n",
    "# input_num = model.classifier[3].in_features\n",
    "# model.classifier[3]=nn.Linear(input_num,num_classes)\n",
    "\n",
    "\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8ffb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data loaders for training, validation, and testing\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=16, shuffle=True, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a8b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa965f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_loss = float('inf')\n",
    "patience = 5  # number of epochs to wait for the loss to decrease\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf01373",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    # Check if the loss has decreased from the previous epoch\n",
    "    if epoch_loss >= prev_loss:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print('Validation loss has not improved for %d epochs. Stopping training.' % patience)\n",
    "            break\n",
    "    else:\n",
    "        counter = 0\n",
    "        prev_loss = epoch_loss\n",
    "    print('the loss havent improved since %d epochs.' %counter)\n",
    "    print(f'Training loss: {epoch_loss}')\n",
    "\n",
    "# Decrease the learning rate by a factor of gamma every step_size epochs\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Evaluate the model on validation data\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    for inputs, labels in tqdm(val_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        val_preds.extend(preds.cpu().numpy())\n",
    "        val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_acc = accuracy_score(val_labels, val_preds)\n",
    "    val_confusion = confusion_matrix(val_labels, val_preds)\n",
    "    print(f'Validation accuracy: {val_acc}')\n",
    "    print(f'Confusion matrix:\\n{val_confusion}')\n",
    "    precision, recall, fscore, support = score(val_labels, val_preds, average='macro')\n",
    "\n",
    "    print('precision: {}'.format(precision))\n",
    "    print('recall: {}'.format(recall))\n",
    "    print('fscore: {}'.format(fscore))\n",
    "    print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19818a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'path + model name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0e6bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the testing set\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "test_loss = 0.0\n",
    "num_samples = 0\n",
    "\n",
    "for inputs, labels in tqdm(test_loader):\n",
    "\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    test_loss += loss.item() * inputs.size(0)\n",
    "    num_samples += inputs.size(0)\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "    y_true += labels.cpu().tolist()\n",
    "    y_pred += predictions.cpu().tolist()\n",
    "\n",
    "test_loss /= num_samples\n",
    "test_acc = accuracy_score(y_true, y_pred)\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "print(f'Test loss: {test_loss}, Test accuracy: {test_acc}')\n",
    "print(f'Confusion matrix:\\n{conf_mat}')\n",
    "\n",
    "precision, recall, fscore, support = score(y_true, y_pred, average='macro')\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b2b2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('path + model name'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
